{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waveletdeboshir/whisper-lang-remover/blob/main/whisper_lang_remover.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9B0lXpHxwTi"
      },
      "source": [
        "# Jupyter for removing unnecessary languages from Whisper ü§´ ü§ó\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thanks https://github.com/avidale for this method https://gist.github.com/avidale/44cd35bfcdaf8bedf51d97c468cc8001"
      ],
      "metadata": {
        "id": "jU8s1_tY4YoP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3N4fqRh-xwTo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HF_HUB_CACHE\"] = \"./models/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9aZvWUqPUv5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import WhisperProcessor, WhisperTokenizer, WhisperForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FijaaGsaxwTr"
      },
      "outputs": [],
      "source": [
        "# Whisper size: tiny, base, small, medium or large-v3\n",
        "size = \"tiny\"\n",
        "new_name = \"ru-pruned\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd models && git clone https://huggingface.co/openai/whisper-{size}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vB2JEWVo3Bpx",
        "outputId": "1a10405a-b60a-4816-c10f-1b0c29367bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'whisper-tiny'...\n",
            "remote: Enumerating objects: 187, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 187 (delta 36), reused 18 (delta 18), pack-reused 133 (from 1)\u001b[K\n",
            "Receiving objects: 100% (187/187), 3.18 MiB | 11.93 MiB/s, done.\n",
            "Resolving deltas: 100% (104/104), done.\n",
            "Filtering content: 100% (4/4), 576.46 MiB | 36.33 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twzaudUaPu7u",
        "outputId": "d8c312d3-7855-45c9-92f8-c53b18972ffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# Load initial model and tokenizer\n",
        "tokenizer = WhisperTokenizer.from_pretrained(f\"models/whisper-{size}\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(f\"models/whisper-{size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl3ktji1xwTs",
        "outputId": "cf013b4e-d85b-48c9-e444-0f1c81234161"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Embedding(51865, 384, padding_idx=50257),\n",
              " Linear(in_features=384, out_features=51865, bias=False))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# We can reduce size of decoder embeddings and last linear layer\n",
        "model.model.decoder.embed_tokens, model.proj_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC3sfRpEQKmx",
        "outputId": "df141ecd-1080-4d1d-bf7e-c5d644af87d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 57676800\n",
            "Number of emb and proj_out parameters: 39832320\n",
            "Proportion of encoder parameters: 0.14231691078561917\n",
            "Proportion of decoder parameters: 0.5123768308921438\n",
            "Proportion of last linear layer parameters: 0.345306258322237\n",
            "Proportion of token embedding parameters: 0.345306258322237\n",
            "Proportion of token embedding + last layer parameters: 0.690612516644474\n"
          ]
        }
      ],
      "source": [
        "# Compute proportion of parameters\n",
        "# last linear layer doesn't present in model parameters so we add it to denominator\n",
        "def msize(m):\n",
        "    return sum(p.numel() for p in m.parameters())\n",
        "\n",
        "init_size = msize(model) + msize(model.proj_out)\n",
        "print(\"Number of parameters:\", init_size)\n",
        "print(\"Number of emb and proj_out parameters:\", msize(model.proj_out) + msize(model.model.decoder.embed_tokens))\n",
        "print(\"Proportion of encoder parameters:\", msize(model.model.encoder) / init_size)\n",
        "print(\"Proportion of decoder parameters:\", msize(model.model.decoder) / init_size)\n",
        "print(\"Proportion of last linear layer parameters:\", msize(model.proj_out) / init_size)\n",
        "print(\"Proportion of token embedding parameters:\", msize(model.model.decoder.embed_tokens) / init_size)\n",
        "print(\"Proportion of token embedding + last layer parameters:\", (msize(model.model.decoder.embed_tokens) + msize(model.proj_out))/ init_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y288PoDrxwTv"
      },
      "source": [
        "Table for understanding proportions.\n",
        "\n",
        "| model | proportion of token embeddings and proj_out layers|\n",
        "| ---- | ---- |\n",
        "| tiny | 0.6906 |\n",
        "| base | 0.5357 |\n",
        "| small | 0.2829 |\n",
        "| ---- | ---- |\n",
        "| medium | 0.1300 |\n",
        "| large-v3 | 0.0825 |\n",
        "\n",
        "It is not so effective to delete tokens from larger whisper models then from smaller."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPmvR6gZxwTv"
      },
      "source": [
        "## Choice of tokens\n",
        "We will\n",
        "* download sentence corpus from https://wortschatz.uni-leipzig.de/en/download/Russian\n",
        "* tokenize it\n",
        "* and calculate most common tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVxiaiChxwTw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "from collections import Counter\n",
        "from tqdm.auto import tqdm, trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "0d5303dea4384954af0d814ed8d4ba15",
            "1b481a69699d4a448b921100feff3831",
            "66c48fccf122498390cc678aac727499",
            "b6bdea5a2fb04c50984025565ccdfc2f",
            "babb4a4ac3ac4badbdfd482df274fe17",
            "49e9b8006cc74cb6af81ca133d0d6d03",
            "ee05c3ab691e4a578a4b101f88faee91",
            "e9d393d7c6f743c4b4a5ff8aa01b48d9",
            "be636a0e016948028fc9baa072e61a89",
            "28a98d43039b4d8d9b4b72c8e4a58523",
            "ad584c2af0ef490cbbf83eaaaa3265cd"
          ]
        },
        "id": "EDkNEyZIQzTL",
        "outputId": "bc399e7f-920b-43cd-98c0-4b0aee74f27b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d5303dea4384954af0d814ed8d4ba15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique tokens: 19126\n",
            "Proportion of russian tokens to tokenizer vocab_size 0.3805563293406025\n"
          ]
        }
      ],
      "source": [
        "# tokenization of sentences\n",
        "df_ru = pd.read_csv('rus-ru_web-public_2019_1M-sentences.txt', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
        "df_ru.columns = ['idx', 'text']\n",
        "cnt_ru = Counter()\n",
        "for text in tqdm(df_ru.text):\n",
        "    cnt_ru.update(tokenizer.encode(text))\n",
        "    # also tokenize sentences with space as first character (to preserve tokens \"between\" 2 sentences)\n",
        "    cnt_ru.update(tokenizer.encode(\" \" + text))\n",
        "print(\"Number of unique tokens:\", len(cnt_ru))\n",
        "print(\"Proportion of russian tokens to tokenizer vocab_size\", len(cnt_ru)/tokenizer.vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqKuR8pjQ4Ig",
        "outputId": "9aba6f73-e18f-48a8-ca3e-e3914d596a97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 0.8197274140404213\n",
            "2500 0.9739719208821588\n",
            "3000 0.9905188788769316\n",
            "4000 0.9963932707126129\n",
            "5000 0.9977663555397532\n",
            "7000 0.9988577621983334\n"
          ]
        }
      ],
      "source": [
        "# Let's look how many tokens can we take from tokenizer\n",
        "for top in 1000, 2500, 3000, 4000, 5000, 7000:\n",
        "    print(top, sum(v for k, v in cnt_ru.most_common(top)) / sum(cnt_ru.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT_Jbut9UpFJ"
      },
      "source": [
        "I will keep:\n",
        "\n",
        "* 10 special tokens (no timestamps, no languages)\n",
        "* 200 first tokens from tokenizer\n",
        "* 4000 most popular tokens for russian language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCMi44GNxwTx"
      },
      "outputs": [],
      "source": [
        "kept_special_tokens = [\n",
        "    '<|endoftext|>',\n",
        "    '<|startoftranscript|>',\n",
        "    '<|en|>',\n",
        "    '<|ru|>',\n",
        "    '<|translate|>',\n",
        "    '<|transcribe|>',\n",
        "    '<|startoflm|>',\n",
        "    '<|startofprev|>',\n",
        "    '<|nocaptions|>',\n",
        "    '<|notimestamps|>'\n",
        "]\n",
        "\n",
        "kept_special_ids = [tokenizer.encode(t, add_special_tokens=False)[0] for t in kept_special_tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vs0KvLZUiEs",
        "outputId": "2eb32dd0-8e57-4abb-d6db-84930ea3cc18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4098 Russan tokens are included\n",
            "Number of kept tokens 4207\n"
          ]
        }
      ],
      "source": [
        "# Adding token ids to list of tokens we will keep\n",
        "# 200 first tokens from tokenizer\n",
        "new_tokens = set(range(200))\n",
        "\n",
        "# most popular russian tokens\n",
        "for i, (k, v) in enumerate(cnt_ru.most_common(5000)):\n",
        "    if len(new_tokens) == 4200:\n",
        "        print(i, 'Russan tokens are included')\n",
        "        break\n",
        "    if k not in new_tokens:\n",
        "        new_tokens.add(k)\n",
        "\n",
        "for t in kept_special_ids:\n",
        "    new_tokens.add(t)\n",
        "\n",
        "print(\"Number of kept tokens\", len(new_tokens))\n",
        "kept_ids = sorted(new_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gu3Tug66xwTy"
      },
      "outputs": [],
      "source": [
        "# check if all russian and english letters are included\n",
        "\n",
        "letters_tokens = []\n",
        "for s in \"–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–ØabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\":\n",
        "    letters_tokens += tokenizer.encode(s, add_special_tokens=False)\n",
        "\n",
        "for t in list(set(letters_tokens)):\n",
        "    if t not in kept_ids:\n",
        "        print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also you can check file `kept_tokens_ru_no_ts.txt` in repo where I saved all kept ids."
      ],
      "metadata": {
        "id": "GlDIj4UcAiSG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQbuGPvIU4Uk"
      },
      "source": [
        "## Update model weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNrA94j5UzRh"
      },
      "outputs": [],
      "source": [
        "new_size = len(kept_ids)\n",
        "\n",
        "# New embedding layer\n",
        "new_emb = torch.nn.Embedding(\n",
        "    new_size,\n",
        "    model.model.decoder.embed_tokens.embedding_dim,\n",
        "    padding_idx=kept_ids.index(50257)  # new idx of <|endoftext|> token\n",
        ")\n",
        "\n",
        "# New proj_out layer\n",
        "new_head = torch.nn.Linear(\n",
        "    in_features=model.proj_out.in_features,\n",
        "    out_features=new_size,\n",
        "    bias=False\n",
        ")\n",
        "\n",
        "# Copying weights\n",
        "for new_id, old_id in enumerate(kept_ids):\n",
        "    new_emb.weight.data[new_id] = model.model.decoder.embed_tokens.weight.data[old_id]\n",
        "    new_head.weight.data[new_id] = model.proj_out.weight.data[old_id]\n",
        "\n",
        "# Change layers in model\n",
        "model.model.decoder.embed_tokens = new_emb\n",
        "model.proj_out = new_head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwr31Kl6xwT0"
      },
      "source": [
        "### Change model config and generation config\n",
        "\n",
        "We need to renumber tokens in configs according to new ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwz7e5QDxwT0"
      },
      "outputs": [],
      "source": [
        "# Change model config\n",
        "\n",
        "model.config.__dict__['vocab_size'] = new_size\n",
        "model.config.__dict__['_name_or_path'] = f'waveletdeboshir/whisper-{size}-{new_name}'\n",
        "\n",
        "\n",
        "\n",
        "model.config.__dict__[\"bos_token_id\"] = kept_ids.index(model.config.__dict__[\"bos_token_id\"])\n",
        "model.config.__dict__[\"decoder_start_token_id\"] = kept_ids.index(model.config.__dict__[\"decoder_start_token_id\"])\n",
        "model.config.__dict__[\"eos_token_id\"] = kept_ids.index(model.config.__dict__[\"eos_token_id\"])\n",
        "model.config.__dict__[\"pad_token_id\"] = kept_ids.index(model.config.__dict__[\"pad_token_id\"])\n",
        "model.config.__dict__[\"suppress_tokens\"] = []\n",
        "model.config.__dict__[\"forced_decoder_ids\"] = [\n",
        "    [\n",
        "      1,\n",
        "      kept_ids.index(50263) # <|ru|>\n",
        "    ],\n",
        "    [\n",
        "      2,\n",
        "      kept_ids.index(50359) # <|transcribe|>\n",
        "    ],\n",
        "    [\n",
        "      3,\n",
        "      kept_ids.index(50363) # <|notimestamps|>\n",
        "    ]\n",
        "]\n",
        "\n",
        "beg_sup = []\n",
        "for t in model.config.__dict__['begin_suppress_tokens']:\n",
        "    if t in kept_ids:\n",
        "        beg_sup.append(kept_ids.index(t))\n",
        "model.config.__dict__['begin_suppress_tokens'] = beg_sup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIimyXP3xwT0"
      },
      "outputs": [],
      "source": [
        "# Change generation config\n",
        "\n",
        "beg_sup = []\n",
        "for t in model.generation_config.__dict__['begin_suppress_tokens']:\n",
        "    if t in kept_ids:\n",
        "        beg_sup.append(kept_ids.index(t))\n",
        "model.generation_config.__dict__['begin_suppress_tokens'] = beg_sup\n",
        "\n",
        "model.generation_config.__dict__[\"bos_token_id\"] = kept_ids.index(model.generation_config.__dict__[\"bos_token_id\"])\n",
        "model.generation_config.__dict__[\"decoder_start_token_id\"] = kept_ids.index(model.generation_config.__dict__[\"decoder_start_token_id\"])\n",
        "model.generation_config.__dict__[\"eos_token_id\"] = kept_ids.index(model.generation_config.__dict__[\"eos_token_id\"])\n",
        "model.generation_config.__dict__[\"forced_decoder_ids\"] = [\n",
        "    [\n",
        "      1,\n",
        "      None\n",
        "    ],\n",
        "    [\n",
        "      2,\n",
        "      kept_ids.index(50359)\n",
        "    ]\n",
        "  ]\n",
        "\n",
        "new_lang_to_id = {}\n",
        "for key, value in model.generation_config.__dict__[\"lang_to_id\"].items():\n",
        "    if value in kept_ids:\n",
        "        new_lang_to_id[key] = kept_ids.index(value)\n",
        "model.generation_config.__dict__[\"lang_to_id\"] = new_lang_to_id\n",
        "\n",
        "model.generation_config.__dict__[\"no_timestamps_token_id\"] = kept_ids.index(model.generation_config.__dict__[\"no_timestamps_token_id\"])\n",
        "model.generation_config.__dict__[\"pad_token_id\"] = kept_ids.index(model.generation_config.__dict__[\"pad_token_id\"])\n",
        "model.generation_config.__dict__[\"prev_sot_token_id\"] = kept_ids.index(model.generation_config.__dict__[\"prev_sot_token_id\"])\n",
        "model.generation_config.__dict__[\"suppress_tokens\"] = []\n",
        "model.generation_config.__dict__[\"task_to_id\"] = {\n",
        "    key: kept_ids.index(value) for key, value in model.generation_config.__dict__[\"task_to_id\"].items()\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLx3mmjdxwT1"
      },
      "source": [
        "### Save pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gquaWSjG27Bg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d1cc6b-aa01-4f74-a09e-b5fb97088974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [200, 4197]}\n"
          ]
        }
      ],
      "source": [
        "model.save_pretrained(f\"models/whisper-{size}-{new_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_YUyEZUxwT1"
      },
      "source": [
        "# Change tokenizer\n",
        "\n",
        "At first it's better to copy all tokenizer files to separate folder `models/tokenizer`.\n",
        "\n",
        "Next we create new folder to save changed tokenizer there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTDK7UQmxwT1"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j0WPYJAxwT1"
      },
      "outputs": [],
      "source": [
        "target_folder = \"ru-tokenizer-nots\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkjAyFyXxwT1"
      },
      "outputs": [],
      "source": [
        "!mkdir ./models/{target_folder}\n",
        "\n",
        "!mkdir ./models/tokenizer\n",
        "!cp ./models/whisper-{size}/added_tokens.json ./models/tokenizer/\n",
        "!cp ./models/whisper-{size}/merges.txt ./models/tokenizer/\n",
        "!cp ./models/whisper-{size}/special_tokens_map.json ./models/tokenizer/\n",
        "!cp ./models/whisper-{size}/tokenizer.json ./models/tokenizer/\n",
        "!cp ./models/whisper-{size}/tokenizer_config.json ./models/tokenizer/\n",
        "!cp ./models/whisper-{size}/vocab.json ./models/tokenizer/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeY0BY4lxwT2"
      },
      "source": [
        "Now we will change ids of tokens in every file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtkckU8tAyIH"
      },
      "outputs": [],
      "source": [
        "# Added tokens\n",
        "with open(\"./models/tokenizer/added_tokens.json\", \"r\") as f:\n",
        "    added_tokens = json.load(f)\n",
        "\n",
        "ch_added_tokens = {}\n",
        "for key, value in added_tokens.items():\n",
        "    if value in kept_ids:\n",
        "        ch_added_tokens[key] = kept_ids.index(value)\n",
        "\n",
        "with open(f\"./models/{target_folder}/added_tokens.json\", \"w\") as f:\n",
        "    json.dump(ch_added_tokens, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(ch_added_tokens.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wkpk-SpL8NDD",
        "outputId": "1aba54ea-f458-4148-d1c0-4f9965afb33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<|en|>',\n",
              " '<|nocaptions|>',\n",
              " '<|notimestamps|>',\n",
              " '<|ru|>',\n",
              " '<|startoflm|>',\n",
              " '<|startofprev|>',\n",
              " '<|startoftranscript|>',\n",
              " '<|transcribe|>',\n",
              " '<|translate|>']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTaJpErwxwT2"
      },
      "outputs": [],
      "source": [
        "# Special tokens map\n",
        "with open(\"./models/tokenizer/special_tokens_map.json\", \"r\") as f:\n",
        "    special_tokens_map = json.load(f)\n",
        "\n",
        "special_tokens_map[\"additional_special_tokens\"] = [\"<|endoftext|>\"] + list(ch_added_tokens.keys())\n",
        "with open(f\"./models/{target_folder}/special_tokens_map.json\", \"w\") as f:\n",
        "    json.dump(special_tokens_map, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hTvLrG2xwT3"
      },
      "outputs": [],
      "source": [
        "# Tokenizer config\n",
        "with open(\"./models/tokenizer/tokenizer_config.json\", \"r\") as f:\n",
        "    tok_config = json.load(f)\n",
        "\n",
        "\n",
        "ch_added_tokens_decoder = {}\n",
        "for key, value in tok_config[\"added_tokens_decoder\"].items():\n",
        "    if int(key) in kept_ids:\n",
        "        ch_added_tokens_decoder[str(kept_ids.index(int(key)))] = value\n",
        "\n",
        "tok_config[\"added_tokens_decoder\"] = ch_added_tokens_decoder\n",
        "tok_config[\"additional_special_tokens\"] = [\"<|endoftext|>\"] + list(ch_added_tokens.keys())\n",
        "\n",
        "with open(f\"./models/{target_folder}/tokenizer_config.json\", \"w\") as f:\n",
        "    json.dump(tok_config, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgGWwTVGxwT3"
      },
      "outputs": [],
      "source": [
        "# Tokenizer\n",
        "with open(\"./models/tokenizer/tokenizer.json\", \"r\") as f:\n",
        "    tok = json.load(f)\n",
        "\n",
        "# change added tokens\n",
        "ch_added_tokens = []\n",
        "for t in tok[\"added_tokens\"]:\n",
        "    if t[\"id\"] in kept_ids:\n",
        "        t[\"id\"] = kept_ids.index(t[\"id\"])\n",
        "        ch_added_tokens.append(t)\n",
        "\n",
        "tok[\"added_tokens\"] = ch_added_tokens\n",
        "\n",
        "# change vocab\n",
        "ch_vocab = {}\n",
        "for key, value in tok[\"model\"][\"vocab\"].items():\n",
        "    if value in kept_ids:\n",
        "        ch_vocab[key] = kept_ids.index(value)\n",
        "\n",
        "tok[\"model\"][\"vocab\"] = ch_vocab\n",
        "\n",
        "# change post processor\n",
        "ch_post = {}\n",
        "for key, value in tok[\"post_processor\"][\"special_tokens\"].items():\n",
        "    if value[\"ids\"][0] in kept_ids:\n",
        "        value[\"ids\"][0] = kept_ids.index(value[\"ids\"][0])\n",
        "        ch_post[key] = value\n",
        "\n",
        "with open(f\"./models/{target_folder}/tokenizer.json\", \"w\") as f:\n",
        "    json.dump(tok, f, indent=4, ensure_ascii=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuGQoa_zxwT3"
      },
      "outputs": [],
      "source": [
        "# Vocab\n",
        "with open(f\"./models/{target_folder}/vocab.json\", \"w\") as f:\n",
        "    json.dump(ch_vocab, f, indent=4, ensure_ascii=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrovvZquxwT4"
      },
      "source": [
        "Merges file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6bc9Ie_xwT5"
      },
      "outputs": [],
      "source": [
        "with open(\"./models/tokenizer/merges.txt\", \"r\") as f:\n",
        "    merges = f.read().split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lajkWfYwxwT5"
      },
      "outputs": [],
      "source": [
        "not_found = []\n",
        "not_found_merged_tokens = []\n",
        "found = []\n",
        "\n",
        "for merge in merges[1:-1]:\n",
        "    m = merge.split()\n",
        "    if (m[0] not in ch_vocab.keys() or m[1] not in ch_vocab.keys() or m[0] in not_found_merged_tokens or m[1] in not_found_merged_tokens) and (m[0] + m[1] not in ch_vocab.keys()):\n",
        "        not_found.append(merge)\n",
        "        not_found_merged_tokens.append(m[0] + m[1])\n",
        "    else:\n",
        "        found.append(merge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzQaMwJKxwT6",
        "outputId": "57a43877-6a21-449d-8784-ea4051840f77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13299"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "len(found)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFGvvdZOxwT6"
      },
      "outputs": [],
      "source": [
        "with open(f\"./models/{target_folder}/merges.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(found))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sZrEMX0MOH6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d9af60b-1805-409b-fe9f-b5d707b6b15c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# Load changed tokenizer from folder\n",
        "changed_tok = WhisperTokenizer.from_pretrained(f\"./models/{target_folder}/\", local_files_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sUz-P5aQxwT7",
        "outputId": "1c0c4fbd-faf5-48a9-c7fe-cae3364cdcf7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|startoftranscript|><|notimestamps|> –•–µ–ª–ª–æ—É, —á—Ç–æ –∑–∞ —Å—Ç—Ä–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–µ—á–µ—á–∫–∏<|endoftext|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Check if it works\n",
        "changed_tok.decode(changed_tok.encode(\" –•–µ–ª–ª–æ—É, —á—Ç–æ –∑–∞ —Å—Ç—Ä–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–µ—á–µ—á–∫–∏\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYhhzN40xwT8"
      },
      "source": [
        "# Try new model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ux5jMvXExwT8"
      },
      "outputs": [],
      "source": [
        "# We need to copy new tokenizer files\n",
        "# normalizer file and preprocessor config from original model\n",
        "!cp ./models/{target_folder}/* ./models/whisper-{size}-{new_name}/\n",
        "!cp ./models/whisper-{size}/normalizer.json ./models/whisper-{size}-{new_name}/\n",
        "!cp ./models/whisper-{size}/preprocessor_config.json ./models/whisper-{size}-{new_name}/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJvT6do7xwT8",
        "outputId": "90e63fa9-607d-4022-c76d-3ef649a6fc5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# Load new model, processor and tokenizer from folder\n",
        "\n",
        "tokenizer = WhisperTokenizer.from_pretrained(f\"./models/whisper-{size}-{new_name}/\", local_files_only=True)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(f\"./models/whisper-{size}-{new_name}\", local_files_only=True)\n",
        "preprocessor = WhisperProcessor.from_pretrained(f\"./models/whisper-{size}-{new_name}\", local_files_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEIv00H7xwT8",
        "outputId": "7da38883-3745-42b5-9daa-0ae08cffe4bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New model size 21075456\n",
            "Ratio of new size to initial size 0.3654061251664447\n"
          ]
        }
      ],
      "source": [
        "# Check new model size\n",
        "print(\"New model size\", msize(model) + msize(model.proj_out))\n",
        "print(\"Ratio of new size to initial size\", (msize(model) + msize(model.proj_out)) / init_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ioy544qxwT9"
      },
      "source": [
        "Check if all works on some test file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTmsS5n8xwT9"
      },
      "outputs": [],
      "source": [
        "import torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/waveletdeboshir/whisper-lang-remover/blob/a3414fdb309393c43f93931b10087c2b7ece5fa0/audio.mp3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SdbaC-LD1SA",
        "outputId": "471eb936-d5db-4927-ab72-d54377fd46c4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-02 18:47:40--  https://github.com/waveletdeboshir/whisper-lang-remover/blob/a3414fdb309393c43f93931b10087c2b7ece5fa0/audio.mp3\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‚Äòaudio.mp3.1‚Äô\n",
            "\n",
            "\raudio.mp3.1             [<=>                 ]       0  --.-KB/s               \raudio.mp3.1             [ <=>                ] 312.44K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-09-02 18:47:40 (41.3 MB/s) - ‚Äòaudio.mp3.1‚Äô saved [319938]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmFEDs8cxwT9",
        "outputId": "014b5896-233b-4247-87ca-82eedd9d2bed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<|startoftranscript|><|ru|><|transcribe|><|notimestamps|> –ó–∞–∫–æ–Ω –±–æ–ª—å—à–∏—Ö –∏ –º–∞–ª—ã—Ö —á–∏—Å–µ–ª –æ–¥–∏–Ω.<|endoftext|>']\n"
          ]
        }
      ],
      "source": [
        "wav, sr = torchaudio.load(\"audio.mp3\")\n",
        "\n",
        "if sr != 16000:\n",
        "    wav = torchaudio.functional.resample(wav, sr, 16000)\n",
        "\n",
        "processed = preprocessor(wav[0], sampling_rate=16000, return_tensors=\"pt\")\n",
        "\n",
        "predicted_ids = model.generate(processed.input_features)\n",
        "\n",
        "transcriptions = preprocessor.batch_decode(predicted_ids, skip_special_tokens=False)\n",
        "\n",
        "print(transcriptions)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d5303dea4384954af0d814ed8d4ba15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b481a69699d4a448b921100feff3831",
              "IPY_MODEL_66c48fccf122498390cc678aac727499",
              "IPY_MODEL_b6bdea5a2fb04c50984025565ccdfc2f"
            ],
            "layout": "IPY_MODEL_babb4a4ac3ac4badbdfd482df274fe17"
          }
        },
        "1b481a69699d4a448b921100feff3831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49e9b8006cc74cb6af81ca133d0d6d03",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ee05c3ab691e4a578a4b101f88faee91",
            "value": "100%"
          }
        },
        "66c48fccf122498390cc678aac727499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9d393d7c6f743c4b4a5ff8aa01b48d9",
            "max": 1000000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be636a0e016948028fc9baa072e61a89",
            "value": 1000000
          }
        },
        "b6bdea5a2fb04c50984025565ccdfc2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28a98d43039b4d8d9b4b72c8e4a58523",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ad584c2af0ef490cbbf83eaaaa3265cd",
            "value": "‚Äá1000000/1000000‚Äá[12:39&lt;00:00,‚Äá1812.10it/s]"
          }
        },
        "babb4a4ac3ac4badbdfd482df274fe17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49e9b8006cc74cb6af81ca133d0d6d03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee05c3ab691e4a578a4b101f88faee91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9d393d7c6f743c4b4a5ff8aa01b48d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be636a0e016948028fc9baa072e61a89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28a98d43039b4d8d9b4b72c8e4a58523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad584c2af0ef490cbbf83eaaaa3265cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}